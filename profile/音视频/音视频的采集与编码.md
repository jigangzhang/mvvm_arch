
## 音视频的采集与编码


#### 音频的采集

    MediaRecorder，上层的API
    AudioRecord，更加接近底层
    OpenSL ES，native层接口
    将PCM数据编码为AAC或者MP3文件
    RECORD_AUDIO 权限，文件权限

    AudioRecord工作流程：
        1、配置参数，初始化内部的音频缓冲区，new AudioRecord()
            bufferSizeInBytes，音频缓冲区大小，该缓冲区越小，产生的延时就会越小，getMinBufferSize获取
            查看当前状态，getState是否是AudioRecord.STATE_INITAILIZED
        2、开始采集，startRecording()
        3、提取数据，read，从缓冲区及时将音频数据取出来（子线程）
        4、保存数据
        5、停止采集，释放资源，最后关闭写入数据的文件
            stop、release

#### 视频画面的采集

    摄像头API
    CAMERA权限
    配置摄像头参数，预览格式一般设置为NV21格式，它实际上就是YUV420SP的格式
    设置预览尺寸，分辨率的尺寸一般设置为 1280X720
    摄像头默认采集出来的视频画面是横板的，显示的时候需要获取当前摄像头采集出来的画面的旋转角度：
        if(FRONT)
            degrees = CameraInfo.orientation % 360;
        else if (BACK)
            degrees = (CameraInfo.orientation + 360) % 360;
    摄像头的预览：
        OpenGL ES渲染图像，先把图像解码为RGBA格式，然后将RGBA格式的字节数组上传到一个纹理上，最终将纹理渲染到屏幕上
        预览过程：开始预览、刷新预览、结束预览
        surfaceTexture = new SurfaceTexture(textureId)  //textureId，纹理ID，从Native层传到Java层
        camera.setPreviewTexture(surfaceTexture)
        surfaceTexture.setOnFrameAvailableListener()
        camera.startPreview()
        绑定纹理时使用：
            glBindTexture(GL_TEXTURE_EXTERNAL_OES, texId)，而不是GL_TEXTURE_2D
        对纹理设置参数时也要使用GL_TEXTURE_EXTERNAL_OES
        fragment shader中声明扩展：
            #extension GL_OES_EGL_image_external : require，放在第一行

        预览角度调整，具体计算见 P144
        将一个特殊格式（OES）的纹理ID经过处理和旋转，使其变成正常格式（RGBA）
        涉及的计算见 P145
        项目 CameraPreview

#### 音频的编码

    MP3格式是兼容性最好的格式
    AAC在低码率（128bit/s一下）场景下，音频品质大大超过MP3
    Ogg格式适用于VOIP通话
    AMR格式适用于语言聊天

    libfdk_aac编码AAC：
        基于FFmpeg的API编写软件编码，只需编写一份音频编码的代码，对于不同的编码器，只需调整相应的编码器ID或者编码器Name
        交叉编译时，必须将第三方库编译到FFmpeg中
        init：
            av_register_all()
            avformat_alloc_output_context2()    //分配出封装格式
            avio_open2()        //传入AAC的编码路径
            audioStream = avformat_new_stream(avFormatContext, NULL)    //为avFormatContext填充一轨AVStream
            audioStream.codec.codec_type = AVMEDIA_TYPE_AUDIO   //为AVCodecContext填充属性
            audioStream.codec.sample_fmt = AV_SAMPLE_FMT_S16    //数字化表示采样，其他属性略
            avcodec_find_encoder_by_name()      //找出对应的编码器
            avcodec_open2()     //为该编码器上下文打开编码器
            为编码器指定frame_size，一般指定1024作为一帧的大小
            某些编码器只允许特定格式的PCM作为输入源，比如LAME不允许SInt16的表示格式
            SwrContext()        //分配重采样上下文
            inputFrame = AVFrame()    //分配输入帧，作为输入的PCM数据存放的地方
            inputFrame分配的buffer大小：bufferSize = frame_size * sizeof(SInt16) * channels
            av_samples_get_buffer_size()    //计算buffer大小，同上
            如果需要进行重采样处理，那就需要额外分配一个重采样之后的AVFrame的swrFrame，作为最终得到结果的AVFrame
            avformat_write_header()     //最后，将该音频文件的Header部分写进去
            isWriteHeaderSuccess = true //在销毁资源阶段需要根据此标志判断是否调用write trailer，写入文件尾部，否则会Crash
        encode(buffer)：
            将buffer填充入inputFrame，buffer大小上面已知
            avcodec_encode_audio2()     //编码，该方法将编码好的数据放入AVPacket
            av_interleaved_write_frame()    //将packet输出到最终的文件中
        destroy：
            销毁分配的资源以及打开的连接通道
            销毁重采样上下文，销毁AVFrame
            isWriteHeaderSuccess为true，填充duration以及调用方法av_write_trailer
            最终关闭编码器以及连接通道

    硬件编码器MediaCodec：
        硬件编码，可以大大提高编码效率，降低电量的使用，但是兼容性不太好（只支持4.1系统以上）
        AAC编码格式有：ADTS封装格式和裸的AAC的封装格式
        MediaCodec编码出来的AAC是裸的AAC（AAC的原始数据块，AAC原始数据块的长度是可变的）
        对原始帧加上ADTS头进行封装，就形成了ADTS帧
        Audio Data Transport Stream，是AAC音频的传输流格式，通常将AAC原始帧加上ADTS头进行封装后写入文件
        ADTS头有7个字节：
            packet[0] = 0xFF;
            packet[1] = 0xF9;   //前2个字节是ADTS的同步字
            int profile = 2; //AAC LC，编码的Profile
            int freqIdx = 4; //44.1kHz，采样率下标
            int chanCfg = 2; //声道配置，不是声道数
            packet[2] = (byte)(((profile - 1) << 6) + (freqIdx << 2) + (chanCfg >> 2));
            packet[3] = (byte)(((chanCfg & 3) << 6) + (packetLen >> 11));
            packet[4] = (byte)((packetLen & 0x7FF) >> 3);
            packet[5] = (byte)(((packetLen & 7) << 5) + 0x1F); //packetLen是原始数据长度加上ADTS头的长度
            packet[6] = (byte) 0xFC;    //固定值
        初始化：
            MediaCodec.createEncoderByType("audio/mp4a-latm");  //找出编码器
            encodeFormat = MediaFormat.createAudioFormat(MINE_TYPE, sampleRate, channels); //配置
            encodeFormat.setInteger(MediaFormat.KEY_BIT_RATE, bitRate);//配置比特率、Profile、输入Buffer的最大值等
            mediaCodec.configure(encodeFormat, null, null, MediaCodec.CONFIGURE_FLAG_ENCODE);//配置到编码器内部
            mediaCodec.start(); //开启编码器
        编码：
            inputBuffers = mediaCodec.getInputBuffers();  //用于存放输入的PCM数据（类似FFmpeg的AVFrame）
            outputBuffers = mediaCodec.getOutputBuffers();  //用于存放编码后的原始AAC数据（类似FFmpeg的AVPacket）
            bufferIndex = codec.dequeueInputBuffer(-1); //读取出一个可用来输入的buffer的index
            if(bufferIndex >= 0) {
                inputBuffer = inputBuffers[bufferIndex];
                inputBuffer.clear();
                inputBuffer.put(data); //填充数据
                codec.queueInputBuffer(bufferIndex, 0, len, System.nanoTime(), 0);  //把填充好的buffer发送给Codec
            }

            info = new BufferInfo();
            index = codec.dequeueOutputBuffer(info, 0);  //从codec读取出一个编码好的buffer的index
            while(index >= 0) {
                outputBuffer = outputBuffers[index]; //通过index读取buffer
                outPacketSize = info.size + 7; //计算总长度，原始数据+ADTS头
                outputBuffer.position(info.offset);
                outputBuffer.limit(info.offset + info.size);
                outData = new byte[outPacketSize];
                addADTStoPacket(outData, outPacketSize);    //添加头
                outputBuffer.get(outData, 7, info.size);    //将AAC原始数据取出到目标数组中
                outputBuffer.position(info.offset);
                saveAACPacket(outData);

                codec.releaseOutputBuffer(index, false);
                index = codec.dequeueOutputBuffer(info, 0);
            }
        销毁：
            mediaCodec.stop();
            mediaCodec.release();

#### 视频画面的编码

    软件编码使用libx264库
    输入摄像头纹理图像，输出是H264的Annexb封装格式的流

    libx264编码H264：
        输入纹理，输出H264裸流
        编码器模块接口：
            VideoEncoderAdapter，编码器模块入口，将输入的纹理ID做转换，使转换后的数据可以作为具体编码器的输入
            void init(path, width, height, bitRate, frameRate)  //视频编码的MetaData信息
            virtual int createEncoder(elgCore, int inputTexId) = 0; //纯虚函数，纹理转换，创建编码器
            virtual void encode() = 0;  //编码
            virtual void destroyEncoder() = 0;  //销毁编码器、销毁OpenGL ES的渲染线程
        两个线程：纹理拷贝线程（生产视频帧放入队列）和编码线程（消费者，从队列取出视频帧进行编码，再输出到文件中）
        VideoFrameQueue，链表 createEncoder中创建，同时还有两个线程的创建
        typedef struct VideoFrame_t {
            unsigned char *buffer;  //YUV420P的图像数据
            int size;   //图像数据大小
            int timeMills;  //所代表的时间戳
            int duration;   //这帧图像所代表的时间长度
        } VideoFrame;
        编码线程：
            encoder = new VideoX264Encoder();
            encoder->init(...);
            LiveVideoFrame *videoFrame = NULL;
            while(true) {
                if(videoFramePool->getYUV2Packet(&videoFrame, true) < 0)    //从队列取出视频帧
                    break;
                if(videoFrame){
                    encoder->encode(videoFrame);    //编码
                    delete videoFrame;
                    videoFrame = NULL;
                }
            }
            if(NULL != encoder){
                encoder->destroy();
                delete encoder;
                encoder = NULL;
            }
        纹理拷贝线程：
            将纹理从显存拷贝到内存中需要耗费的时间比较长，为不阻塞预览的渲染线程，因此建立了纹理拷贝线程
            使用OpenGL的共享上下文，创建OpenGL ES上下文的时候，使用已经存在的EGLContext
            与渲染线程（EGLContext）共享所有的OpenGL对象（纹理对象、帧缓存对象，等等）
            createOffscreenSurface，makeCurrent
            纹理拷贝所需的输出纹理ID和帧缓存对象：
                glGenFramebuffers(1, &mFBO);
                glGenTextures(1, &outputTexId);
            拷贝前，先绑定该帧的缓存对象，然后使用renderer（将输入纹理ID绘制到绑定的帧缓存对象上）
            renderer的渲染目标就是绑定的这个帧的缓存对象，而输出纹理ID是绑定到这个帧缓存对象的，所有相当于将输入纹理的内容绘制到了输出纹理上了
                glViewport(0, 0, videoWidth, videoHeight);
                glBindFramebuffer(GL_FRAMEBUFFER, mFBO);
                checkGlError("fbo err");
                long startTime = getCurrentTime();
                renderer->renderToTexture(texId, outputTexId);
                glBindFramebuffer(GL_FRAMEBUFFER, 0);   //解绑
            拷贝成功之前，需要阻塞预览线程（encode方法使用条件锁wait），拷贝成功后，拷贝线程发送signal指令（encode接收到signal指令后就可以结束，让预览线程继续）
            将输出纹理ID的内容拷贝到内存中，显存和内存的数据交换，X264的输入必须是内存中的数据
            glReadPixels，显存到内存的数据转换API，读取RGBA格式的数据时，分辨率越大读取一帧数据耗费的时间就越多
            把显存到内存中的数据交换（耗时、性能低）和拷贝纹理（速度快）分为两个阶段
            显存到内存的数据转换的优化，主要就是减少数据量的读取，可以把RGBA格式的纹理ID先转换为ＹＵＹ２的格式
            ＹＵＹ２把一个像素使用２个字节表示（RGBA使用４个），数据量减少一半
            在显存中通过OpenGL Program将RGBA格式转化为YUY2格式，然后再读取，将YUY2格式的数据进行编码
            VideoX264Encoder主要完成将YUY2的原始图像数据编码成H264的压缩数据，写到文件中
            从YUY2到YUV420P格式具体转换过程，见源码（P172），在armv7平台上利用Neon指令集来做加速，在X86平台使用SSE指令集来做加速

    硬件编码器MediaCodec：
        Android4.3之后，通过Surface配置编码器的输入，大大降低了显存到内存的交换过程所使用的时间
        MediaCodec允许直接以显存中的纹理对象作为输入（libx264以内存中的数据作为输入，需要进行显存到内存的数据交换），速度更快

        codec = new MediaCodec()，MediaCodec实例的编码类型为“video/avc”
        codec.configure()，配置编码器
        createInputSurface，创建MediaCodec的输入Surface
        codec.start()，开启编码器
        Native层：
        用上面创建的Surface构造一个ANativeWindow，与预览线程的OpenGL上下文共同创建EGLSurface
        创建renderer将输入纹理ID渲染到目标Surface上
        在新线程中拉取MediaCodec编码的H264数据，用jbyteArray
        MediaCodec编码的H264数据，会在前几帧中返回SPS和PPS信息，需要将它们作为全局变量存储，放到每一个关键帧前面，组成H264文件
        判断H264帧的NALU Type
        编码：
        把第一次编码取得的当前时间戳记录为开始编码的时间戳 startTime
        之后调用编码操作的时候，取出当前时间减去startTime，算出编码时长，然后根据帧率和编码时长算出编码数目 expectedFrameCnt
        在每编码一帧的时候就为全局变量encodedFrameCnt加1
        通过比较expectedFrameCnt和encodedFrameCnt，控制是否将这一帧视频帧发送给编码器
        发送给编码器的这一帧视频帧的时间戳就是上面计算的时长
            if(startTime == -1)
                startTime = getCurrentTime();
            curTime = getCurrentTime() - startTime;
            expectedFameCount = (int)(curTime/1000.0f * frameRate + 0.5f); //计算编码数目
            if(expectedFameCount < encodedFameCount)
                return;
            encodedFameCount++;
            if(EGL_NO_SURFACE != encoderSurface) {
                makeCurrent;    //egl，将encoderSurface作为渲染目标
                renderToView;   //调用renderer将输入的纹理ID渲染到Surface上
                setPresentationTime;    //为编码器设置编码的时间
                postMessage;    //向拉取编码数据的线程发送指令，让其到MediaCodec拉取H264数据
                swapBuffer;     //渲染数据
            }
        拉取编码数据的线程：
            调用Java层MediaCodec.dequeueOutputBuffer，判断返回值状态对应处理
            如果状态正常且大于0，就取出对应的编码数据，将buffer数据复制出来，调用MediaCodec.release将buffer放回到缓存队列
            在Native层拿到数据，用该buffer数据中index为4的数据与0X1F做 & 操作判断NALU类型，如果是SPS和PPS，就存储到全局变量
            int nalu_type = (outputData[4] & 0x1F);
            if(H264_NALU_TYPE_SEQUENCE_PARAMETER_SET == nalu_type) {
                spsppsBufferSize = size;
                spsppsBuffer = new byte[spsppsBufferSize];
                memcpy(spsppsBuffer, outputData, spsppsBufferSize);
            } else if(NULL != spsppsBuffer) {
                if(H264_NALU_TYPE_IDR_PICTURE == nalu_type) {
                    fwrite(spsppsBuffer, 1, spsppsBufferSize, h264File);    //写SPS PPS
                }
                fwrite(outputData, size, h264File);
            }
        销毁编码器：
            停止拉取编码器数据的线程
            关闭MediaCodec，释放相关的编码器资源
            释放分配的jbyteArray的buffer，释放SPS和PPS的buffer
            最后关闭文件
